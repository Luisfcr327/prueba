{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42c85d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime as dt, timedelta\n",
    "import teradata\n",
    "import pyodbc\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "405d4aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tIniciando sesión en Teradata...\n",
      "\n",
      "\tHaciendo consulta Teradata\n",
      "\n",
      "\tConsulta realizada\n",
      "\n",
      "\tIniciando sesión en Teradata...\n",
      "\n",
      "\tHaciendo consulta Teradata\n",
      "\n",
      "\tConsulta realizada\n",
      "\n",
      "\tCargando archivo\n",
      "\n",
      "\tArchivo guardado con exito\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCORRIJA Y AGREGUE LOS CASOS MANUALES / APRIETE CUALQUIER TECLA PARA CONTINUAR \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tAsignando secuencias\n",
      "\n",
      "\tConexion exitosa\n",
      "\n",
      "\tHaciendo consulta SQL\n",
      "\n",
      "\tConsulta realizada\n",
      "\n",
      "\tCargando historico\n",
      "\n",
      "\tHistorico guardado con exito\n",
      "\n",
      "\tArmando Hoja Errores y hoja Itiim\n",
      "\n",
      "\tCargando archivo\n",
      "\n",
      "\tArchivo guardado con exito\n"
     ]
    }
   ],
   "source": [
    "#Lee el archivo de los proveedores\n",
    "def leer_archivos():\n",
    "    \n",
    "    #Especificar la ulr para agarrar todos los archivos de ahi, de momento no tengo la url de una compartida entonces por el momento no importa\n",
    "    #url = \"\"\n",
    "    nombre_cts = \"CTS 13 Julio 25.xlsx\"\n",
    "    nombre_int = \"Inteneg 13 Julio 25.xlsx\"\n",
    "    \n",
    "    url_cts = nombre_cts\n",
    "    url_int = nombre_int\n",
    "    \n",
    "    dtype = {\n",
    "        'Cuenta' : str,\n",
    "        'Tarjeta' : str,\n",
    "        'Autorizacion1' : str\n",
    "    }\n",
    "\n",
    "    #Lee los archivos tal cual como vienen en el sharepoint\n",
    "    df_cts = pd.read_excel(url_cts, dtype=dtype, parse_dates=[\"Fcompra1\"])\n",
    "    df_int = pd.read_excel(url_int, dtype = dtype, parse_dates=[\"Fcompra1\"])\n",
    "    \n",
    "    df_cts[\"Fcompra1\"] = df_cts[\"Fcompra1\"].dt.strftime(\"%d/%m/%Y\")\n",
    "    df_int[\"Fcompra1\"] = df_int[\"Fcompra1\"].dt.strftime(\"%d/%m/%Y\")\n",
    "    \n",
    "    \n",
    "    #Esto junta los dos df en uno solo pero no se si es necesario tenerlos separados o si si se puede tenerlos juntos\n",
    "    df_prove = pd.concat([df_cts,df_int])\n",
    "    \n",
    "    return df_prove\n",
    "\n",
    "def quitar_duplicados(df):\n",
    "\n",
    "    #Crea la llave\n",
    "    df[\"Llave\"] = df[\"Cuenta\"] + df[\"Autorizacion1\"] + df[\"Monto1\"].astype(str) + df[\"Fcompra1\"].astype(str) + df[\"Txn1\"].astype(str)\n",
    "    \n",
    "    #Borramos los duplicados\n",
    "    duplicados = df[df.duplicated(subset=\"Llave\", keep=\"first\")].copy()\n",
    "    duplicados[\"Errores\"] = \"Transacción duplicada\"\n",
    "    df = df.drop_duplicates(subset = 'Llave')\n",
    "\n",
    "    \n",
    "    \n",
    "    return df, duplicados\n",
    "    \n",
    "def abrir_db():\n",
    "#Conexion a la base de datos\n",
    "    server = \"MP-VW-DB-004\"\n",
    "    database = \"master\"\n",
    "\n",
    "\n",
    "    conn_str = (\n",
    "        f\"DRIVER={{ODBC Driver 17 for SQL Server}};\"\n",
    "        f\"SERVER={server};\"\n",
    "        f\"DATABASE={database};\"\n",
    "        f\"Trusted_Connection=yes;\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        connection=pyodbc.connect(conn_str)\n",
    "        print(\"\\n\\tConexion exitosa\")\n",
    "    except Exception as e:\n",
    "            print(\"Error en la conexion: \",e)\n",
    "            \n",
    "    return connection\n",
    "                    \n",
    "def ejecutar_query(query,connection):\n",
    "\n",
    "    print(\"\\n\\tHaciendo consulta SQL\")\n",
    "    #Creamos el objeto cursor para poder ejecutar consultas\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # Realizar las consultas y el resultado lo guardamos en otro dataframe\n",
    "    df = pd.read_sql(query, connection)\n",
    "    print(\"\\n\\tConsulta realizada\")     \n",
    "    \n",
    "    return df\n",
    "    \n",
    "def cerrar_db(connection):\n",
    "    # Cerrar la conexión\n",
    "    connection.close()\n",
    "    \n",
    "    return connection\n",
    "\n",
    "def formato_SQL(df,columna):\n",
    "    \n",
    "    #Convertir columnas en formato SQL (con comillas y coma) para la consulta SQL ejemplo 123456 va a ser igual a '123456',\n",
    "    lista_formato_SQL = df[columna].tolist()\n",
    "    lista_formato_SQL= ', '.join(f\"'{tarjeta}'\" for tarjeta in lista_formato_SQL)\n",
    "    \n",
    "    return lista_formato_SQL\n",
    "\n",
    "\n",
    "def query_arqa(cuentas):\n",
    "\n",
    "    query = f\"\"\"/****** Script for SelectTopNRows command from SSMS  ******/\n",
    "    SELECT CONCAT(Numero_cuenta,floor(Plan_de_Venta)) as Llave,\n",
    "           [Numero_Cuenta]\n",
    "          ,[Tipo_Plan]\n",
    "          ,[Secuencia]\n",
    "          ,[Store]\n",
    "          ,[Plan_de_Venta]\n",
    "          ,[Status_Plan]\n",
    "          ,[Fecha_Apertura_Plan]\n",
    "          ,[Importe]\n",
    "          ,[ORG]\n",
    "          ,[LOGO]\n",
    "          ,[Fecha_Carga]\n",
    "      FROM [VISION_FILES].[dbo].[Reporte_ARQA]\n",
    "      Where Numero_Cuenta in ({cuentas})\n",
    "\n",
    "    Order by Fecha_Apertura_Plan desc\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    return query\n",
    "\n",
    "def teradata_sebas(consulta_por):\n",
    "\n",
    "    query = f\"\"\"SELECT  \n",
    "    substr(NUM_CAR_CARF,4,16) as PAN\n",
    "    ,NUM_CTA_CTAF as CTA \n",
    "    ,VAL_TRANS_COM as IMPORTE\n",
    "    ,DAT_TRANS_COM as FECHA_TXN\n",
    "    ,NOM_ESTB_FPRO as NOMBRE_COMERCIO\n",
    "    ,NUM_REF_COM as REF_TXN\n",
    "    ,NOM_FANT_CARF as NOMBRE_CLIENTE\n",
    "    ,substr(X.VAL_DADO_ORIG_LKP,4,5) AS PLAN \n",
    "    ,NUM_AUT_COM\n",
    "    ,DAT_PROX_CORTE_FAT_ATRF AS Prox_Corte\n",
    "    ,COD_TIPO_TRANSACAO_FPRO\n",
    "    \n",
    "    FROM CARTAO_FINANCIAMENTO_V\t\n",
    "    \n",
    "    INNER JOIN CONTA_FINANCIAMENTO_V\n",
    "    ON ID_CTA_CARF = ID_CTA_CTAF\n",
    "    \n",
    "    LEFT OUTER JOIN COMPRA_V\n",
    "    ON ID_CAR_COM = ID_CAR_CARF\n",
    "    \n",
    "    INNER JOIN PLANO_CREDITO_V X\n",
    "    ON ID_PLANO_CRED_COM = X.ID_PLANO_CRED_LKP\n",
    "    \n",
    "    INNER JOIN TIPO_TRANSACAO_V\n",
    "    ON ID_TIPO_TRANS_COM = ID_TIPO_TRANS_LKP\n",
    "    \n",
    "    LEFT OUTER JOIN FAT_TRANSACAO_PROSA_V\n",
    "    ON ID_CAR_FPRO = ID_CAR_COM\n",
    "    AND NUM_REF_FPRO = NUM_REF_COM\n",
    "     \n",
    "    inner join ATRIBUTO_CONTA_FINANCIAMENTO_V\n",
    "    on ID_CTA_CTAF = ID_CTA_ATRF and current_date between DAT_DE_ATRF and DAT_ATE_ATRF\n",
    "     \n",
    "    WHERE\n",
    "    {consulta_por}\n",
    "    --and COD_TIPO_TRANSACAO_FPRO in ('01') \n",
    "    and DAT_TRANS_COM >= CURRENT_DATE - INTERVAL '60' DAY\n",
    "    and substr(X.VAL_DADO_ORIG_LKP,4,5) in ('01000','01100','01181','06000')\n",
    "    \"\"\"\n",
    "    return query\n",
    "    \n",
    "def conexion_a_teradata():\n",
    "    \n",
    "    try:\n",
    "        print('\\n\\tIniciando sesión en Teradata...')\n",
    "    \n",
    "        host: str = '192.168.17.64'  # Dirección IP o nombre del servidor Teradata\n",
    "        user: str = 'MPROC_GR'       # Usuario de Teradata\n",
    "        password: str = 'padrao' # Contraseña de Teradata\n",
    "        driver: str = \"Teradata Database ODBC Driver 20.00\"  # Controlador ODBC\n",
    "\n",
    "        udaExec = teradata.UdaExec(appName=\"PythonApp\", version=\"1.0\", logConsole=False)\n",
    "\n",
    "        session = udaExec.connect(\n",
    "\n",
    "            method=\"odbc\",\n",
    "            system=host,\n",
    "            username=user,\n",
    "            password=password,\n",
    "            driver=driver,\n",
    "            sslmode='Allow'\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error en la conexión a Teradata: {str(e)}\")\n",
    "        return None  # Retorna None en caso de error\n",
    "    \n",
    "    return session\n",
    "\n",
    "    \n",
    "def hacer_consulta(session, query):\n",
    "\n",
    "    print(\"\\n\\tHaciendo consulta Teradata\")\n",
    "    session.execute(\"DATABASE PM_MstrDB\")\n",
    "    df = pd.read_sql(query, session)\n",
    "    print(\"\\n\\tConsulta realizada\")\n",
    "    return df\n",
    "\n",
    "def cerrar_conexion(session):\n",
    "    session.close()\n",
    "\n",
    "    \n",
    "def cruces(df,df_teradata,parametro_teradata,parametro_df,corregir_cuentas):\n",
    "    \n",
    "    #Crear una llave en terada cuenta&aut&monto&fecha o tarjeta&aut&monto&fecha depende del parametro\n",
    "    df_teradata[\"Llave_completa\"] = df_teradata[parametro_teradata] + df_teradata[\"NUM_AUT_COM\"] + df_teradata[\"IMPORTE\"].astype(str) + df_teradata[\"FECHA_TXN\"].astype(str) + df_teradata[\"PLAN\"].astype(str)\n",
    "    df[\"Llave_completa\"] = df[parametro_df] + df[\"Autorizacion1\"] + df[\"Monto1\"].astype(str) + df[\"Fcompra1\"].astype(str) + df[\"Txn1\"].astype(str)\n",
    "    \n",
    "    #Busca en las dos consultas de teradata si se encuentran esos casos y asi saber que todos los campos de la llave estan bien\n",
    "    df_bien = df[df['Llave_completa'].isin(set(df_teradata['Llave_completa']))]\n",
    "    \n",
    "    #Cuando las cuentas estan mal (se hizo la consulta por tarjeta y coincidieron casos), asignar la cuenta de teradata\n",
    "    if corregir_cuentas == True:\n",
    "        df_bien = pd.merge(df_bien, df_teradata[[\"Llave_completa\", \"CTA\"]], on=\"Llave_completa\", how=\"left\")\n",
    "        df_bien[\"Cuenta\"] = df_bien[\"CTA\"]\n",
    "        df_bien.drop(['CTA'], axis=1, inplace=True)\n",
    "        \n",
    "    \n",
    "    #Los que no tienen algun campo bien, averiguar que campo esta mal y poner el correcto?\n",
    "    df_mal = df[~df['Llave_completa'].isin(set(df_teradata['Llave_completa']))]\n",
    "    \n",
    "    return df_bien, df_mal\n",
    "    \n",
    "    \n",
    "def correccion_datos(df_mal, df_teradata, parametro_teradata, parametro_df):\n",
    "    \n",
    "    #Crea la llave corta en teradata cuenta&aut o tarjeta&aut\n",
    "    df_teradata[\"Llave\"] = df_teradata[parametro_teradata] + df_teradata[\"NUM_AUT_COM\"]\n",
    "    df_mal[\"Llave\"] = df_mal[parametro_df] + df_mal[\"Autorizacion1\"]\n",
    "    \n",
    "    df_no_estan = df_mal[~df_mal[\"Llave\"].isin(set(df_teradata['Llave']))]\n",
    "    df_mal = df_mal[df_mal[\"Llave\"].isin(set(df_teradata['Llave']))]\n",
    "    \n",
    "    df_mal = pd.merge(df_mal, df_teradata[[\"Llave\", \"CTA\", \"IMPORTE\", \"FECHA_TXN\", \"PLAN\"]], on=\"Llave\", how=\"left\")\n",
    "    \n",
    "    df_mal[\"Cuenta\"] = df_mal[\"CTA\"]\n",
    "    df_mal[\"Monto1\"] = df_mal[\"IMPORTE\"]\n",
    "    df_mal[\"Fcompra1\"] = df_mal[\"FECHA_TXN\"]\n",
    "    df_mal[\"Txn1\"] = df_mal[\"PLAN\"]\n",
    "\n",
    "    df_mal.drop(['IMPORTE', 'FECHA_TXN', 'PLAN', 'CTA'], axis=1, inplace=True)\n",
    "    \n",
    "    return df_mal,df_no_estan\n",
    "    \n",
    "def consultar_teradata(consulta_por):\n",
    "\n",
    "    #Hace la consulta en teradata hace la consulta por cuentas, se indica si se consulta por cuenta o por tarjeta\n",
    "    session = conexion_a_teradata()\n",
    "    df_teradata = hacer_consulta(session, teradata_sebas(consulta_por))\n",
    "    cerrar_conexion(session)\n",
    "   \n",
    "\n",
    "    #Cambiar el formato de la fecha a dd/mm/aaaa\n",
    "    df_teradata['FECHA_TXN'] = pd.to_datetime(df_teradata['FECHA_TXN'], dayfirst=True, errors='coerce')\n",
    "    df_teradata['FECHA_TXN'] = df_teradata['FECHA_TXN'].dt.strftime('%d/%m/%Y')\n",
    "    df_teradata['IMPORTE'] = df_teradata['IMPORTE'].map(lambda x: ('%.2f' % x).rstrip('0').rstrip('.') if '.' in ('%.2f' % x) else '%.2f' % x)\n",
    "    df_teradata[\"PLAN\"] = df_teradata[\"PLAN\"].astype(int)\n",
    "    df_teradata[\"PAN\"] = \"000\" + df_teradata[\"PAN\"].astype(str)\n",
    "\n",
    "    df_teradata = df_teradata[~df_teradata[\"COD_TIPO_TRANSACAO_FPRO\"].isin([\"21\"])]\n",
    "    \n",
    "    return df_teradata\n",
    "\n",
    "def exportar_archivo(df, df_no_estan, df_corregidos,df_errores,df_itim,url):\n",
    "    with pd.ExcelWriter(url) as writer:\n",
    "        df.to_excel(writer, \"Completo\", index=False)\n",
    "        df_no_estan.to_excel(writer,\"No estan en Teradata\", index=False)\n",
    "        df_corregidos.to_excel(writer, \"Todos corregidos\", index=False)\n",
    "        df_errores.to_excel(writer, \"Errores\", index=False)\n",
    "        df_itim.to_excel(writer, \"ITIIM\", index=False)\n",
    "        \n",
    "        \n",
    "    print(\"\\n\\tArchivo guardado con exito\")\n",
    "\n",
    "\n",
    "def corregir_aut(df, df_teradata,parametro_teradata, parametro_df):\n",
    "\n",
    "    #Crea la llave sin aut\n",
    "    df_teradata[\"Llave\"] = df_teradata[parametro_teradata] + df_teradata[\"IMPORTE\"].astype(str) + df_teradata[\"FECHA_TXN\"].astype(str) + df_teradata[\"PLAN\"].astype(str)\n",
    "    df[\"Llave\"] = df[parametro_df] + df[\"Monto1\"].astype(str) + df[\"Fcompra1\"].astype(str) + df[\"Txn1\"].astype(str)\n",
    "\n",
    "    df_no_estan = df[~df[\"Llave\"].isin(set(df_teradata['Llave']))]\n",
    "    df_mal = df[df[\"Llave\"].isin(set(df_teradata['Llave']))]\n",
    "    \n",
    "    df_mal = pd.merge(df_mal, df_teradata[[\"Llave\", \"CTA\", \"NUM_AUT_COM\"]], on=\"Llave\", how=\"left\")\n",
    "    \n",
    "    df_mal[\"Cuenta\"] = df_mal[\"CTA\"]\n",
    "    df_mal[\"Autorizacion1\"] = df_mal[\"NUM_AUT_COM\"]\n",
    "\n",
    "\n",
    "    df_mal.drop(['NUM_AUT_COM', 'CTA'], axis=1, inplace=True)\n",
    "    \n",
    "    return df_mal,df_no_estan\n",
    "    \n",
    "    \n",
    "def definir_errores(df_mal, df_cuentas_mal, df_cuen_fech_impo_mal,df_aut_mal,df_aut_cuenta_mal,df_estan_historico, df_duplicados):\n",
    "\n",
    "    df_cuentas_mal[\"Errores\"] = \"Cuentas erroneas\"\n",
    "    df_aut_mal[\"Errores\"] = \"Autorizador incorrecto\"\n",
    "    df_aut_cuenta_mal[\"Errores\"] = \"Cuenta y aut incorrecto\"\n",
    "    df_cuen_fech_impo_mal[\"Errores\"] = \"Cuenta erronea ademas de Fecha, monto o plan incorrecto\"\n",
    "    df_mal[\"Errores\"] = \"Fecha, monto o plan incorrecto\"\n",
    "\n",
    "    \n",
    "    df_errores = pd.concat([\n",
    "        df_mal,\n",
    "        df_cuentas_mal,\n",
    "        df_cuen_fech_impo_mal,\n",
    "        df_aut_mal,\n",
    "        df_aut_cuenta_mal,\n",
    "        df_estan_historico,\n",
    "        df_duplicados\n",
    "    ], ignore_index=True)\n",
    "\n",
    "    return df_errores\n",
    "    \n",
    "    \n",
    "def proceso(df):\n",
    "    \n",
    "    #Convierte todas las cuentas en formato SQL\n",
    "    cuentas = formato_SQL(df, \"Cuenta\")\n",
    "    tarjetas = formato_SQL(df,\"Tarjeta\")\n",
    "    \n",
    "    #Linea que sirve para complementar el query para saber por que consultar\n",
    "    consultar_por_cuenta = f\"NUM_CTA_CTAF IN ({cuentas})\"\n",
    "    consultar_por_tarjeta = f\"NUM_CAR_CARF IN ({tarjetas})\"\n",
    "    \n",
    "    #Quita los 0 que no nos sirven\n",
    "    df['Monto1'] = df['Monto1'].map(lambda x: ('%.2f' % x).rstrip('0').rstrip('.') if '.' in ('%.2f' % x) else '%.2f' % x)\n",
    "    \n",
    "    #Vamos a hacer la consulta de teradata por cuenta, por lo que el segundo parametro no importa ahorita (no importa la tarjeta por eso los 0000000)\n",
    "    df_teradata = consultar_teradata(consultar_por_cuenta)\n",
    "    #Hace los cruces con teradata usando la llave completa, cuenta como uno de los parametros\n",
    "    #En caso de que no encuentre en teradata, hace los cruces con cuenta&aut y asigna las fehcas y montos\n",
    "    #Identifica los que aun asi  noestan\n",
    "    #Se indica que no se van a corregir las cuentas con el false\n",
    "    df_bien, df_mal = cruces(df, df_teradata, \"CTA\", \"Cuenta\", False)\n",
    "    df_aut_mal,df_no_estan = corregir_aut(df_mal, df_teradata, \"CTA\", \"Cuenta\")\n",
    "    df_mal,df_no_estan = correccion_datos(df_no_estan,df_teradata, \"CTA\", \"Cuenta\")\n",
    "    \n",
    "    #Hace los cruces con teradata usando la llave completa, tarjeta como uno de los parametros\n",
    "    #En caso de que no encuentre en teradata, hace los cruces con tarjeta&aut y asigna las fehcas y montos\n",
    "    #Identifica los que aun asi  noestan\n",
    "    #Vamos a hacer la consulta de teradata por tarjeta, por lo que el segundo parametro no importa ahorita (no importa la cuenta por eso los 0000000)\n",
    "    #Se indica que no se van a corregir las cuentas con el false\n",
    "    df_teradata = consultar_teradata(consultar_por_tarjeta)    \n",
    "    print(\"\\n\\tCargando archivo\")\n",
    "    df_cuentas_mal, df_todo_mal = cruces(df_no_estan, df_teradata, \"PAN\", \"Tarjeta\", True)\n",
    "    df_aut_cuenta_mal,df_cuen_fech_impo_mal = corregir_aut(df_todo_mal,df_teradata, \"PAN\", \"Tarjeta\")\n",
    "    df_cuen_fech_impo_mal,df_no_estan = correccion_datos(df_cuen_fech_impo_mal,df_teradata, \"PAN\", \"Tarjeta\")\n",
    "    \n",
    "    #Concatenar todos los df corregidos en uno solo (menos el completo y los manuales) \n",
    "    df_corregidos = pd.concat([\n",
    "        df_bien,\n",
    "        df_mal,\n",
    "        df_cuentas_mal,\n",
    "        df_cuen_fech_impo_mal,\n",
    "        df_aut_mal,\n",
    "        df_aut_cuenta_mal\n",
    "    ], ignore_index=True)\n",
    "    \n",
    "\n",
    "    df_corregidos, df_duplicados = quitar_duplicados(df_corregidos)\n",
    "    \n",
    "    url = \"C:\\\\Users\\\\MX50086\\\\Downloads\\\\Parcializaciones\\\\casos.xlsx\"\n",
    "\n",
    "    df_errores = pd.DataFrame(columns=[\"Aquí van a ir los errores\"])\n",
    "    df_itim = pd.DataFrame(columns=[\"Aquí van a ir el itim\"])\n",
    "\n",
    "    #df_corregidos = asignar_secuencia_tienda(df_corregidos)\n",
    "    \n",
    "    #Exporta el archivo con todos los df, se hacen los casos manuales y se agregan a la hoja de \"Todos corregidos\" del excel, luego compara todos con el historico\n",
    "    exportar_archivo(df,df_no_estan,df_corregidos,df_errores,df_itim, url)\n",
    "    \n",
    "    input(\"\\n\\tCORRIJA Y AGREGUE LOS CASOS MANUALES / APRIETE CUALQUIER TECLA PARA CONTINUAR\")\n",
    "\n",
    "    print(\"\\n\\tAsignando secuencias\")\n",
    "    df_corregidos = asignar_secuencia_tienda(df_corregidos)\n",
    "    \n",
    "    print(\"\\n\\tCargando historico\")\n",
    "    df_corregidos, df_estan_historico = comparar_con_historico(df_corregidos)\n",
    "    \n",
    "    print(\"\\n\\tArmando Hoja Errores y hoja Itiim\")\n",
    "    df_errores = definir_errores(df_mal, df_cuentas_mal, df_cuen_fech_impo_mal,df_aut_mal,df_aut_cuenta_mal,df_estan_historico,df_duplicados)\n",
    "    \n",
    "    df_itim = armar_itim(df_corregidos)\n",
    "    df_inclusiones = armar_inclusiones(df_corregidos)\n",
    "    df_itim = pd.concat([df_itim,df_inclusiones])\n",
    "\n",
    "    print(\"\\n\\tCargando archivo\")\n",
    "    exportar_archivo(df,df_no_estan,df_corregidos,df_errores,df_itim, url)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "def comparar_con_historico(df):\n",
    "    \n",
    "    nombre_historico = \"Historico.xlsx\"\n",
    "    #Esto es por si no se encuentra en la ruta del codigo\n",
    "    url_historico = nombre_historico\n",
    "    \n",
    "    dtype = {\n",
    "        \"Cuenta\" : str,\n",
    "        \"Tarjeta\" : str,\n",
    "        \"Autorizacion1\": str,\n",
    "        \"PS\" : str,\n",
    "        \"Store\" : str,\n",
    "    }\n",
    "    \n",
    "    \n",
    "    #Que el historico sea de una sola hoja, no separada por socios\n",
    "    df_historico = pd.read_excel(url_historico, dtype=dtype, parse_dates=[\"Fcompra1\"])\n",
    "\n",
    "    #Poner las columnas fecha e importe con el mismo formato a los del df\n",
    "    df_historico['Fcompra1'] = pd.to_datetime(df_historico['Fcompra1'], dayfirst=True, errors='coerce')\n",
    "    df_historico['Fcompra1'] = df_historico['Fcompra1'].dt.strftime('%d/%m/%Y')\n",
    "    df_historico['Monto1'] = df_historico['Monto1'].map(lambda x: ('%.2f' % x).rstrip('0').rstrip('.') if '.' in ('%.2f' % x) else '%.2f' % x)\n",
    "\n",
    "    df['Fcompra1'] = pd.to_datetime(df['Fcompra1'], dayfirst=False, errors='coerce')\n",
    "    df['Fcompra1'] = df['Fcompra1'].dt.strftime('%d/%m/%Y')\n",
    "    df['Monto1'] = df['Monto1'].astype(float)\n",
    "    df['Monto1'] = df['Monto1'].map(lambda x: ('%.2f' % x).rstrip('0').rstrip('.') if '.' in ('%.2f' % x) else '%.2f' % x)\n",
    "    \n",
    "    \n",
    "    #Crear llave completa para el historico\n",
    "    df_historico[\"Llave_completa\"] = df_historico[\"Cuenta\"] + df_historico[\"Autorizacion1\"] + df_historico[\"Monto1\"].astype(str) + df_historico[\"Fcompra1\"].astype(str) + df_historico[\"Txn1\"].astype(str)\n",
    "    \n",
    "    #Creamos de nuevo la llave del df debido a que la anterior estaba con los datos incorrectos (Se corrigeron todos los datos menos los de la llave)\n",
    "    df[\"Llave_completa\"] = df[\"Cuenta\"] + df[\"Autorizacion1\"] + df[\"Monto1\"].astype(str) + df[\"Fcompra1\"].astype(str) + df[\"Txn1\"].astype(str)\n",
    "    \n",
    "    \n",
    "    #Elimina del df los que estan en el historico\n",
    "    df_estan_historico = df[df[\"Llave_completa\"].isin(set(df_historico['Llave_completa']))]\n",
    "    df = df[~df[\"Llave_completa\"].isin(set(df_historico['Llave_completa']))]\n",
    "    \n",
    "    df_estan_historico[\"Errores\"] = \"Ya esta parcializada\"\n",
    "    \n",
    "    exportar_historico(df,df_historico)\n",
    "    \n",
    "    return df, df_estan_historico\n",
    "    \n",
    "def exportar_historico(df, df_historico):\n",
    "    \n",
    "    nombre_historico = \"Historico.xlsx\"\n",
    "    #Esto es por si no se encuentra en la ruta del codigo\n",
    "    url_historico = nombre_historico\n",
    "    \n",
    "    df_hoy = df.drop(['Llave',  'Llave_completa'], axis=1)\n",
    "    df_historico = df_historico.drop(\"Llave_completa\", axis=1)\n",
    "    df_historico = pd.concat([df_hoy, df_historico], ignore_index=True)\n",
    "    \n",
    "    with pd.ExcelWriter(url_historico) as writer:\n",
    "        df_historico.to_excel(writer, \"Historico\", index=False)\n",
    "\n",
    "    print(\"\\n\\tHistorico guardado con exito\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def asignar_secuencia_tienda(df):\n",
    "    \n",
    "    #Hace la consulta sql por cuenta\n",
    "    cuentas = formato_SQL(df,\"Cuenta\")\n",
    "    \n",
    "    conn = abrir_db()\n",
    "    df_sql = ejecutar_query(query_arqa(cuentas), conn)\n",
    "    cerrar_db(conn)\n",
    "    \n",
    "    #Da el formato a los campos importantes\n",
    "    df_sql['Fecha_Apertura_Plan'] = pd.to_datetime(df_sql['Fecha_Apertura_Plan'], dayfirst=True, errors='coerce')\n",
    "    df_sql[\"Plan_de_Venta\"] = df_sql[\"Plan_de_Venta\"].astype(int) \n",
    "    \n",
    "    df['Fcompra1'] = pd.to_datetime(df['Fcompra1'], dayfirst=True, errors='coerce')\n",
    "    \n",
    "    \n",
    "    #Crea las llaves para hacer cruces\n",
    "    df_sql[\"Llave\"] = df_sql[\"Numero_Cuenta\"] + df_sql[\"Plan_de_Venta\"].astype(str)\n",
    "    df[\"Llave\"] = df[\"Cuenta\"] + df[\"Txn1\"].astype(str)\n",
    "    \n",
    "    #Hace los cruces para traerse todas las tiendas y las secuencias de sql de todos los casos\n",
    "    df_con_secuencia = pd.merge(df, df_sql[[\"Llave\", \"Secuencia\", \"Store\", \"Fecha_Apertura_Plan\"]], on=\"Llave\", how=\"left\")\n",
    "    \n",
    "    #Elimina las que sean despues de la fecha de compra\n",
    "    df_con_secuencia = df_con_secuencia[df_con_secuencia['Fecha_Apertura_Plan'] <= df_con_secuencia['Fcompra1']]\n",
    "\n",
    "    #Ordena de mas reciente a mas antigua\n",
    "    df_con_secuencia = df_con_secuencia.sort_values(by='Fecha_Apertura_Plan', ascending=False)\n",
    "    \n",
    "    #Elimina duplicados dejando el primero para tener el mas reciente\n",
    "    df_con_secuencia = df_con_secuencia.drop_duplicates(subset = \"Llave_completa\", keep='first')\n",
    "\n",
    "    #Hacemos este cruce de nuuevo solo para ver si algun dato esta vacio\n",
    "    df =pd.merge(df,df_con_secuencia[[\"Llave_completa\", \"Secuencia\", \"Store\"]], on=\"Llave_completa\", how=\"left\")\n",
    "\n",
    "    df = df.rename(columns={'Secuencia': 'PS'})\n",
    "    \n",
    "    return df\n",
    "\n",
    "def armar_itim(df):\n",
    "\n",
    "    df_itim = pd.DataFrame()\n",
    "    df_itim[\"Cuenta\"] = df[\"Cuenta\"]\n",
    "    df_itim[\"Parcialidad\"] = \"0\"\n",
    "    df_itim[\"Fecha\"] =  df[\"Fcompra1\"]\n",
    "    df_itim[\"Monto de la compra\"] = df[\"Monto1\"]\n",
    "    df_itim[\"Plan\"] = df[\"Txn1\"]\n",
    "    df_itim[\"Secuencia\"] = df[\"PS\"]\n",
    "    df_itim[\"Tienda\"] = df[\"Store\"]\n",
    "    df_itim[[\"Transaccion\", \"Descripcion\"]] = df[\"TipoParcializacion\"].map({\n",
    "    \"PF\": (\"823\", \"AJUSTE POR PROMOCION PAGOS FIJOS        \"),\n",
    "    \"MSI\": (\"821\", \"AJUSTE PROMOCION SIN INTERES RED        \")\n",
    "    }).apply(pd.Series)\n",
    "\n",
    "    return df_itim\n",
    "\n",
    "def definir_plan_pf(parcialidad):\n",
    "\n",
    "    caso = {\n",
    "        \"3\": \"3103\",\n",
    "        \"6\": \"3116\",\n",
    "        \"9\": \"3104\"\n",
    "    }\n",
    "\n",
    "    return caso[parcialidad]\n",
    "\n",
    "def definir_plan_msi(parcialidad):\n",
    "\n",
    "    caso = {\n",
    "        \"4\": \"3173\",\n",
    "        \"6\": \"3176\",\n",
    "        \"9\": \"3179\",\n",
    "        \"12\": \"3170\",\n",
    "    }\n",
    "\n",
    "    return caso[parcialidad]\n",
    "\n",
    "\n",
    "def armar_itim_inclusiones(df, tipo_parci):\n",
    "    \n",
    "    hoy = dt.now()\n",
    "    hoy = str(hoy.strftime(\"%d/%m/%Y\"))\n",
    "\n",
    "    df_inclusiones = pd.DataFrame()\n",
    "    \n",
    "    df_inclusiones[\"Cuenta\"] = df[\"Cuenta\"]\n",
    "    df_inclusiones[\"Parcialidad\"] = df[\"Pagos\"]\n",
    "    df_inclusiones[\"Fecha\"] = hoy\n",
    "    df_inclusiones[\"Monto de la compra\"] = df[\"Monto1\"]\n",
    "    df_inclusiones[\"Secuencia\"] = \"0\"\n",
    "    df_inclusiones[\"Tienda\"] = df[\"Store\"]\n",
    "    if tipo_parci == \"PF\":\n",
    "        plan = []\n",
    "        for index,row in df.iterrows():\n",
    "            plan.append(definir_plan_pf(str(row[\"Pagos\"])))\n",
    "        df_inclusiones[\"Plan\"] = plan\n",
    "        df_inclusiones[\"Transaccion\"] = \"822\"\n",
    "        df_inclusiones[\"Descripcion\"] = \"INC PROMOCION PAGOS FIJOS               \"\n",
    "    else:\n",
    "        plan = []\n",
    "        for index,row in df.iterrows():\n",
    "            plan.append(definir_plan_msi(str(row[\"Pagos\"])))\n",
    "        df_inclusiones[\"Plan\"] = plan\n",
    "        df_inclusiones[\"Transaccion\"] = \"820\"\n",
    "        df_inclusiones[\"Descripcion\"] = \"INC PROMOCION MSI                       \"\n",
    "\n",
    "    return df_inclusiones\n",
    "\n",
    "def armar_inclusiones(df):\n",
    "\n",
    "    df[\"Cuenta_parci\"] = df[\"Cuenta\"].astype(str) + df[\"Pagos\"].astype(str)\n",
    "    df[\"Monto1\"] = df[\"Monto1\"].astype(float)\n",
    "    df = df.groupby(\"Cuenta_parci\", as_index=False).agg({\n",
    "    \"Monto1\": \"sum\",\n",
    "    \"Cuenta\": \"first\",\n",
    "    \"Pagos\": \"first\",\n",
    "    \"Txn1\": \"first\",\n",
    "    \"Store\": \"first\",\n",
    "    \"TipoParcializacion\": \"first\"\n",
    "    })\n",
    "\n",
    "    \n",
    "    #Separarlas por df o MSI\n",
    "    df_pf = df[df[\"TipoParcializacion\"] == \"PF\"].copy()\n",
    "    df_msi = df[df[\"TipoParcializacion\"] == \"MSI\"].copy()\n",
    "\n",
    "    df_pf_inclusiones = armar_itim_inclusiones(df_pf, \"PF\")\n",
    "    df_msi_inclusiones = armar_itim_inclusiones(df_msi, \"MSI\")\n",
    "    \n",
    "    #Concatenar los dos df\n",
    "    df_inclusiones = pd.concat([df_pf_inclusiones,df_msi_inclusiones])\n",
    "\n",
    "    return df_inclusiones\n",
    "    \n",
    "    \n",
    "    \n",
    "def main():\n",
    "    \n",
    "    \n",
    "    #Para no hacer todo dos veces en caso de qu los df se deban mantener separados, se puede crear una funcion en donde se ponga \n",
    "    #todos los pasos y de parametro reciba un df, finalmente en el main llamamos a esa funcio dos veces una por cada df\n",
    "    warnings.filterwarnings('ignore')\n",
    "    df_prove = leer_archivos()\n",
    "    proceso(df_prove)\n",
    "    \n",
    "    #print(df_bien)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "main()\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
