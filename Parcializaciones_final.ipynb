{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42c85d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime as dt, timedelta\n",
    "import teradata\n",
    "import pyodbc\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "405d4aea",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '\\\\\\\\celerrabr\\\\Compartido\\\\Entre_Sesiones\\\\D7627S042\\\\MIS Operaciones\\\\Parcializaciones\\\\Angelica\\\\Parcializacion\\\\B -Bases CTS trabajadas\\\\CTS 17 Julio 25.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 657\u001b[0m\n\u001b[0;32m    650\u001b[0m     proceso(df_prove)\n\u001b[0;32m    652\u001b[0m     \u001b[38;5;66;03m#print(df_bien)\u001b[39;00m\n\u001b[1;32m--> 657\u001b[0m main()\n",
      "Cell \u001b[1;32mIn[2], line 649\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m    644\u001b[0m     \n\u001b[0;32m    645\u001b[0m     \n\u001b[0;32m    646\u001b[0m     \u001b[38;5;66;03m#Para no hacer todo dos veces en caso de qu los df se deban mantener separados, se puede crear una funcion en donde se ponga \u001b[39;00m\n\u001b[0;32m    647\u001b[0m     \u001b[38;5;66;03m#todos los pasos y de parametro reciba un df, finalmente en el main llamamos a esa funcio dos veces una por cada df\u001b[39;00m\n\u001b[0;32m    648\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 649\u001b[0m     df_prove \u001b[38;5;241m=\u001b[39m leer_archivos()\n\u001b[0;32m    650\u001b[0m     proceso(df_prove)\n",
      "Cell \u001b[1;32mIn[2], line 19\u001b[0m, in \u001b[0;36mleer_archivos\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m dtype \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCuenta\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTarjeta\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAutorizacion1\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;28mstr\u001b[39m\n\u001b[0;32m     16\u001b[0m }\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m#Lee los archivos tal cual como vienen en el sharepoint\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m df_cts \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(url_cts, dtype\u001b[38;5;241m=\u001b[39mdtype, parse_dates\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFcompra1\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     20\u001b[0m df_int \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(url_int, dtype \u001b[38;5;241m=\u001b[39m dtype, parse_dates\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFcompra1\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     22\u001b[0m df_cts[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFcompra1\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df_cts[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFcompra1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    494\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m     io \u001b[38;5;241m=\u001b[39m ExcelFile(\n\u001b[0;32m    496\u001b[0m         io,\n\u001b[0;32m    497\u001b[0m         storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    498\u001b[0m         engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[0;32m    499\u001b[0m         engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[0;32m    500\u001b[0m     )\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1550\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1548\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1550\u001b[0m     ext \u001b[38;5;241m=\u001b[39m inspect_excel_format(\n\u001b[0;32m   1551\u001b[0m         content_or_path\u001b[38;5;241m=\u001b[39mpath_or_buffer, storage_options\u001b[38;5;241m=\u001b[39mstorage_options\n\u001b[0;32m   1552\u001b[0m     )\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1554\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1557\u001b[0m         )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1402\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1400\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m   1403\u001b[0m     content_or_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m, storage_options\u001b[38;5;241m=\u001b[39mstorage_options, is_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1404\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m   1405\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   1406\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[0;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '\\\\\\\\celerrabr\\\\Compartido\\\\Entre_Sesiones\\\\D7627S042\\\\MIS Operaciones\\\\Parcializaciones\\\\Angelica\\\\Parcializacion\\\\B -Bases CTS trabajadas\\\\CTS 17 Julio 25.xlsx'"
     ]
    }
   ],
   "source": [
    "#Lee el archivo de los proveedores\n",
    "def leer_archivos():\n",
    "    \n",
    "    #Especificar la ulr para agarrar todos los archivos de ahi, de momento no tengo la url de una compartida entonces por el momento no importa\n",
    "    url = r\"\\\\celerrabr\\Compartido\\Entre_Sesiones\\D7627S042\\MIS Operaciones\\Parcializaciones\\Angelica\\Parcializacion\\B -Bases CTS trabajadas\"\n",
    "    nombre_cts = \"\\CTS 17 Julio 25.xlsx\"\n",
    "    nombre_int = \"\\Inteneg 17 Julio 25.xlsx\"\n",
    "    \n",
    "    url_cts = url + nombre_cts\n",
    "    url_int = url + nombre_int\n",
    "    \n",
    "    dtype = {\n",
    "        'Cuenta' : str,\n",
    "        'Tarjeta' : str,\n",
    "        'Autorizacion1' : str\n",
    "    }\n",
    "\n",
    "    #Lee los archivos tal cual como vienen en el sharepoint\n",
    "    df_cts = pd.read_excel(url_cts, dtype=dtype, parse_dates=[\"Fcompra1\"])\n",
    "    df_int = pd.read_excel(url_int, dtype = dtype, parse_dates=[\"Fcompra1\"])\n",
    "    \n",
    "    df_cts[\"Fcompra1\"] = df_cts[\"Fcompra1\"].dt.strftime(\"%d/%m/%Y\")\n",
    "    df_int[\"Fcompra1\"] = df_int[\"Fcompra1\"].dt.strftime(\"%d/%m/%Y\")\n",
    "    \n",
    "    #Esto junta los dos df en uno solo pero no se si es necesario tenerlos separados o si si se puede tenerlos juntos\n",
    "    df_prove = pd.concat([df_cts,df_int])\n",
    "    \n",
    "    return df_prove\n",
    "\n",
    "def quitar_duplicados(df):\n",
    "\n",
    "    #Crea la llave\n",
    "    df[\"Llave\"] = df[\"Cuenta\"] + df[\"Autorizacion1\"] + df[\"Monto1\"].astype(str) + df[\"Fcompra1\"].astype(str) + df[\"Txn1\"].astype(str)\n",
    "    \n",
    "    #Borramos los duplicados\n",
    "    duplicados = df[df.duplicated(subset=\"Llave\", keep=\"first\")].copy()\n",
    "    duplicados[\"Errores\"] = \"Transacción duplicada\"\n",
    "    df = df.drop_duplicates(subset = 'Llave')\n",
    "\n",
    "    \n",
    "    \n",
    "    return df, duplicados\n",
    "    \n",
    "def abrir_db():\n",
    "#Conexion a la base de datos\n",
    "    server = \"MP-VW-DB-004\"\n",
    "    database = \"master\"\n",
    "\n",
    "\n",
    "    conn_str = (\n",
    "        f\"DRIVER={{ODBC Driver 17 for SQL Server}};\"\n",
    "        f\"SERVER={server};\"\n",
    "        f\"DATABASE={database};\"\n",
    "        f\"Trusted_Connection=yes;\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        connection=pyodbc.connect(conn_str)\n",
    "        print(\"\\n\\tConexion exitosa\")\n",
    "    except Exception as e:\n",
    "            print(\"Error en la conexion: \",e)\n",
    "            \n",
    "    return connection\n",
    "                    \n",
    "def ejecutar_query(query,connection):\n",
    "\n",
    "    print(\"\\n\\tHaciendo consulta SQL\")\n",
    "    #Creamos el objeto cursor para poder ejecutar consultas\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # Realizar las consultas y el resultado lo guardamos en otro dataframe\n",
    "    df = pd.read_sql(query, connection)\n",
    "    print(\"\\n\\tConsulta realizada\")     \n",
    "    \n",
    "    return df\n",
    "    \n",
    "def cerrar_db(connection):\n",
    "    # Cerrar la conexión\n",
    "    connection.close()\n",
    "    \n",
    "    return connection\n",
    "\n",
    "def formato_SQL(df,columna):\n",
    "    \n",
    "    #Convertir columnas en formato SQL (con comillas y coma) para la consulta SQL ejemplo 123456 va a ser igual a '123456',\n",
    "    lista_formato_SQL = df[columna].tolist()\n",
    "    lista_formato_SQL= ', '.join(f\"'{tarjeta}'\" for tarjeta in lista_formato_SQL)\n",
    "    \n",
    "    return lista_formato_SQL\n",
    "\n",
    "\n",
    "def query_arqa(cuentas):\n",
    "\n",
    "    query = f\"\"\"/****** Script for SelectTopNRows command from SSMS  ******/\n",
    "    SELECT CONCAT(Numero_cuenta,floor(Plan_de_Venta)) as Llave,\n",
    "           [Numero_Cuenta]\n",
    "          ,[Tipo_Plan]\n",
    "          ,[Secuencia]\n",
    "          ,[Store]\n",
    "          ,[Plan_de_Venta]\n",
    "          ,[Status_Plan]\n",
    "          ,[Fecha_Apertura_Plan]\n",
    "          ,[Importe]\n",
    "          ,[ORG]\n",
    "          ,[LOGO]\n",
    "          ,[Fecha_Carga]\n",
    "      FROM [VISION_FILES].[dbo].[Reporte_ARQA]\n",
    "      Where Numero_Cuenta in ({cuentas})\n",
    "\n",
    "    Order by Fecha_Apertura_Plan desc\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    return query\n",
    "\n",
    "def teradata_sebas(consulta_por):\n",
    "\n",
    "    query = f\"\"\"SELECT  \n",
    "    substr(NUM_CAR_CARF,4,16) as PAN\n",
    "    ,NUM_CTA_CTAF as CTA \n",
    "    ,VAL_TRANS_COM as IMPORTE\n",
    "    ,DAT_TRANS_COM as FECHA_TXN\n",
    "    ,NOM_ESTB_FPRO as NOMBRE_COMERCIO\n",
    "    ,NUM_REF_COM as REF_TXN\n",
    "    ,NOM_FANT_CARF as NOMBRE_CLIENTE\n",
    "    ,substr(X.VAL_DADO_ORIG_LKP,4,5) AS PLAN \n",
    "    ,NUM_AUT_COM\n",
    "    ,DAT_PROX_CORTE_FAT_ATRF AS Prox_Corte\n",
    "    ,COD_TIPO_TRANSACAO_FPRO\n",
    "    \n",
    "    FROM CARTAO_FINANCIAMENTO_V\t\n",
    "    \n",
    "    INNER JOIN CONTA_FINANCIAMENTO_V\n",
    "    ON ID_CTA_CARF = ID_CTA_CTAF\n",
    "    \n",
    "    LEFT OUTER JOIN COMPRA_V\n",
    "    ON ID_CAR_COM = ID_CAR_CARF\n",
    "    \n",
    "    INNER JOIN PLANO_CREDITO_V X\n",
    "    ON ID_PLANO_CRED_COM = X.ID_PLANO_CRED_LKP\n",
    "    \n",
    "    INNER JOIN TIPO_TRANSACAO_V\n",
    "    ON ID_TIPO_TRANS_COM = ID_TIPO_TRANS_LKP\n",
    "    \n",
    "    LEFT OUTER JOIN FAT_TRANSACAO_PROSA_V\n",
    "    ON ID_CAR_FPRO = ID_CAR_COM\n",
    "    AND NUM_REF_FPRO = NUM_REF_COM\n",
    "     \n",
    "    inner join ATRIBUTO_CONTA_FINANCIAMENTO_V\n",
    "    on ID_CTA_CTAF = ID_CTA_ATRF and current_date between DAT_DE_ATRF and DAT_ATE_ATRF\n",
    "     \n",
    "    WHERE\n",
    "    {consulta_por}\n",
    "    --and COD_TIPO_TRANSACAO_FPRO in ('01') \n",
    "    and DAT_TRANS_COM >= CURRENT_DATE - INTERVAL '60' DAY\n",
    "    and substr(X.VAL_DADO_ORIG_LKP,4,5) in ('01000','01100','01181','06000')\n",
    "    \"\"\"\n",
    "    return query\n",
    "    \n",
    "def conexion_a_teradata():\n",
    "    \n",
    "    try:\n",
    "        print('\\n\\tIniciando sesión en Teradata...')\n",
    "    \n",
    "        host: str = '192.168.17.64'  # Dirección IP o nombre del servidor Teradata\n",
    "        user: str = 'MPROC_GR'       # Usuario de Teradata\n",
    "        password: str = 'padrao' # Contraseña de Teradata\n",
    "        driver: str = \"Teradata Database ODBC Driver 20.00\"  # Controlador ODBC\n",
    "\n",
    "        udaExec = teradata.UdaExec(appName=\"PythonApp\", version=\"1.0\", logConsole=False)\n",
    "\n",
    "        session = udaExec.connect(\n",
    "\n",
    "            method=\"odbc\",\n",
    "            system=host,\n",
    "            username=user,\n",
    "            password=password,\n",
    "            driver=driver,\n",
    "            sslmode='Allow'\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error en la conexión a Teradata: {str(e)}\")\n",
    "        return None  # Retorna None en caso de error\n",
    "    \n",
    "    return session\n",
    "\n",
    "    \n",
    "def hacer_consulta(session, query):\n",
    "\n",
    "    print(\"\\n\\tHaciendo consulta Teradata\")\n",
    "    session.execute(\"DATABASE PM_MstrDB\")\n",
    "    df = pd.read_sql(query, session)\n",
    "    print(\"\\n\\tConsulta realizada\")\n",
    "    return df\n",
    "\n",
    "def cerrar_conexion(session):\n",
    "    session.close()\n",
    "\n",
    "    \n",
    "def cruces(df,df_teradata,parametro_teradata,parametro_df,corregir_cuentas):\n",
    "    \n",
    "    #Crear una llave en terada cuenta&aut&monto&fecha o tarjeta&aut&monto&fecha depende del parametro\n",
    "    df_teradata[\"Llave_completa\"] = df_teradata[parametro_teradata] + df_teradata[\"NUM_AUT_COM\"] + df_teradata[\"IMPORTE\"].astype(str) + df_teradata[\"FECHA_TXN\"].astype(str) + df_teradata[\"PLAN\"].astype(str)\n",
    "    df[\"Llave_completa\"] = df[parametro_df] + df[\"Autorizacion1\"] + df[\"Monto1\"].astype(str) + df[\"Fcompra1\"].astype(str) + df[\"Txn1\"].astype(str)\n",
    "    \n",
    "    #Busca en las dos consultas de teradata si se encuentran esos casos y asi saber que todos los campos de la llave estan bien\n",
    "    df_bien = df[df['Llave_completa'].isin(set(df_teradata['Llave_completa']))]\n",
    "\n",
    "    df_errores_cuenta = df_bien\n",
    "\n",
    "    llaves_a_eliminar = df_bien['Llave_completa'].copy()\n",
    "    \n",
    "    #Cuando las cuentas estan mal (se hizo la consulta por tarjeta y coincidieron casos), asignar la cuenta de teradata\n",
    "    if corregir_cuentas == True:\n",
    "        df_bien = pd.merge(df_bien, df_teradata[[\"Llave_completa\", \"CTA\"]], on=\"Llave_completa\", how=\"left\")\n",
    "        df_bien[\"Cuenta\"] = df_bien[\"CTA\"]\n",
    "        df_bien.drop(['CTA'], axis=1, inplace=True)\n",
    "        \n",
    "    \n",
    "    #Los que no tienen algun campo bien, averiguar que campo esta mal y poner el correcto?\n",
    "    df_mal = df[~df['Llave_completa'].isin(set(df_teradata['Llave_completa']))]\n",
    "\n",
    "    df_teradata = df_teradata[~df_teradata['Llave_completa'].isin(llaves_a_eliminar)]\n",
    "    \n",
    "    return df_bien, df_mal, df_errores_cuenta, df_teradata\n",
    "    \n",
    "    \n",
    "def correccion_datos(df_mal, df_teradata, parametro_teradata, parametro_df):\n",
    "    \n",
    "    #Crea la llave corta en teradata cuenta&aut o tarjeta&aut\n",
    "    df_teradata[\"Llave\"] = df_teradata[parametro_teradata] + df_teradata[\"NUM_AUT_COM\"]\n",
    "    df_mal[\"Llave\"] = df_mal[parametro_df] + df_mal[\"Autorizacion1\"]\n",
    "    \n",
    "    df_no_estan = df_mal[~df_mal[\"Llave\"].isin(set(df_teradata['Llave']))]\n",
    "    df_mal = df_mal[df_mal[\"Llave\"].isin(set(df_teradata['Llave']))]\n",
    "\n",
    "    df_errores_monto_fecha = df_mal\n",
    "    \n",
    "    df_mal = pd.merge(df_mal, df_teradata[[\"Llave\", \"CTA\", \"IMPORTE\", \"FECHA_TXN\", \"PLAN\"]], on=\"Llave\", how=\"left\")\n",
    "    \n",
    "    df_mal[\"Cuenta\"] = df_mal[\"CTA\"]\n",
    "    df_mal[\"Monto1\"] = df_mal[\"IMPORTE\"]\n",
    "    df_mal[\"Fcompra1\"] = df_mal[\"FECHA_TXN\"]\n",
    "    df_mal[\"Txn1\"] = df_mal[\"PLAN\"]\n",
    "\n",
    "    df_mal.drop(['IMPORTE', 'FECHA_TXN', 'PLAN', 'CTA'], axis=1, inplace=True)\n",
    "    \n",
    "    return df_mal,df_no_estan, df_errores_monto_fecha\n",
    "    \n",
    "def consultar_teradata(consulta_por):\n",
    "\n",
    "    #Hace la consulta en teradata hace la consulta por cuentas, se indica si se consulta por cuenta o por tarjeta\n",
    "    session = conexion_a_teradata()\n",
    "    df_teradata = hacer_consulta(session, teradata_sebas(consulta_por))\n",
    "    cerrar_conexion(session)\n",
    "   \n",
    "\n",
    "    #Cambiar el formato de la fecha a dd/mm/aaaa\n",
    "    df_teradata['FECHA_TXN'] = pd.to_datetime(df_teradata['FECHA_TXN'], dayfirst=True, errors='coerce')\n",
    "    df_teradata['FECHA_TXN'] = df_teradata['FECHA_TXN'].dt.strftime('%d/%m/%Y')\n",
    "    df_teradata['IMPORTE'] = df_teradata['IMPORTE'].map(lambda x: ('%.2f' % x).rstrip('0').rstrip('.') if '.' in ('%.2f' % x) else '%.2f' % x)\n",
    "    df_teradata[\"PLAN\"] = df_teradata[\"PLAN\"].astype(int)\n",
    "    df_teradata[\"PAN\"] = \"000\" + df_teradata[\"PAN\"].astype(str)\n",
    "\n",
    "    df_teradata = df_teradata[~df_teradata[\"COD_TIPO_TRANSACAO_FPRO\"].isin([\"21\"])]\n",
    "    \n",
    "    return df_teradata\n",
    "\n",
    "def exportar_archivo(df, df_no_estan, df_corregidos,df_errores,df_itim,url):\n",
    "    with pd.ExcelWriter(url) as writer:\n",
    "        df.to_excel(writer, \"Completo\", index=False)\n",
    "        df_no_estan.to_excel(writer,\"No estan en Teradata\", index=False)\n",
    "        df_corregidos.to_excel(writer, \"Todos corregidos\", index=False)\n",
    "        df_errores.to_excel(writer, \"Errores\", index=False)\n",
    "        df_itim.to_excel(writer, \"ITIIM\", index=False)\n",
    "        \n",
    "        \n",
    "    print(\"\\n\\tArchivo guardado con exito\")\n",
    "\n",
    "\n",
    "def corregir_aut(df, df_teradata,parametro_teradata, parametro_df):\n",
    "\n",
    "    #Crea la llave sin aut\n",
    "    df_teradata[\"Llave\"] = df_teradata[parametro_teradata] + df_teradata[\"IMPORTE\"].astype(str) + df_teradata[\"FECHA_TXN\"].astype(str) + df_teradata[\"PLAN\"].astype(str)\n",
    "    df[\"Llave\"] = df[parametro_df] + df[\"Monto1\"].astype(str) + df[\"Fcompra1\"].astype(str) + df[\"Txn1\"].astype(str)\n",
    "\n",
    "    df_no_estan = df[~df[\"Llave\"].isin(set(df_teradata['Llave']))]\n",
    "    df_mal = df[df[\"Llave\"].isin(set(df_teradata['Llave']))]\n",
    "\n",
    "    llaves_a_eliminar = df_mal['Llave'].copy()\n",
    "\n",
    "    df_errores_aut = df_mal\n",
    "    df_mal = pd.merge(df_mal, df_teradata[[\"Llave\", \"CTA\", \"NUM_AUT_COM\"]], on=\"Llave\", how=\"left\")\n",
    "    \n",
    "    df_mal[\"Cuenta\"] = df_mal[\"CTA\"]\n",
    "    df_mal[\"Autorizacion1\"] = df_mal[\"NUM_AUT_COM\"]\n",
    "\n",
    "\n",
    "    df_mal.drop(['NUM_AUT_COM', 'CTA'], axis=1, inplace=True)\n",
    "\n",
    "    df_teradata = df_teradata[~df_teradata['Llave'].isin(llaves_a_eliminar)]\n",
    "    \n",
    "    return df_mal,df_no_estan, df_errores_aut, df_teradata\n",
    "\n",
    "    \n",
    "def definir_errores(df_errores_aut, df_errores_monto_fecha, df_errores_cuenta, df_errores_cuenta_aut, df_errores_cuenta_fecha_monto, df_estan_historico,df_duplicados):\n",
    "\n",
    "\n",
    "    df_errores_aut[\"Errores\"] = \"Autorizador incorrecto\" \n",
    "    df_errores_monto_fecha[\"Errores\"] = \"Monto Fecha o plan incorrecto\"  \n",
    "    df_errores_cuenta[\"Errores\"] = \"Cuenta errorena\" \n",
    "    df_errores_cuenta_aut[\"Errores\"] = \"Cuenta y autorizador incorrecto\" \n",
    "    df_errores_cuenta_fecha_monto[\"Errores\"] = \"Cuenta y fecha, plan o monto incorrecto\"  \n",
    "    \n",
    "    df_errores = pd.concat([\n",
    "\n",
    "        df_errores_aut, \n",
    "        df_errores_monto_fecha, \n",
    "        df_errores_cuenta, \n",
    "        df_errores_cuenta_aut, \n",
    "        df_errores_cuenta_fecha_monto, \n",
    "        df_estan_historico,df_duplicados\n",
    "        \n",
    "    ], ignore_index=True)\n",
    "\n",
    "    return df_errores\n",
    "    \n",
    "def quitar_corregidos_en_teradata(df_bien, df_aut_mal, df_mal, df_teradata):\n",
    "\n",
    "        \n",
    "    df_corregidos = pd.concat([\n",
    "        df_bien, \n",
    "        df_aut_mal, \n",
    "        df_mal\n",
    "    ], ignore_index=True)\n",
    "\n",
    "    df_corregidos[\"Llave\"] = df_corregidos[\"Cuenta\"] + df_corregidos[\"Autorizacion1\"] + df_corregidos[\"Monto1\"].astype(str) + df_corregidos[\"Fcompra1\"].astype(str) + df_corregidos[\"Txn1\"].astype(str)\n",
    "    df_teradata[\"Llave\"] = df_teradata[\"CTA\"] + df_teradata[\"NUM_AUT_COM\"] + df_teradata[\"IMPORTE\"].astype(str) + df_teradata[\"FECHA_TXN\"].astype(str) + df_teradata[\"PLAN\"].astype(str)\n",
    "\n",
    "    df_teradata = df_teradata[~df_teradata['Llave'].isin(set(df_corregidos['Llave']))]\n",
    "\n",
    "    return df_teradata\n",
    "    \n",
    "\n",
    "\n",
    "def proceso(df):\n",
    "    \n",
    "    #Convierte todas las cuentas en formato SQL\n",
    "    cuentas = formato_SQL(df, \"Cuenta\")\n",
    "    tarjetas = formato_SQL(df,\"Tarjeta\")\n",
    "    \n",
    "    #Linea que sirve para complementar el query para saber por que consultar\n",
    "    consultar_por_cuenta = f\"NUM_CTA_CTAF IN ({cuentas})\"\n",
    "    consultar_por_tarjeta = f\"NUM_CAR_CARF IN ({tarjetas})\"\n",
    "    \n",
    "    #Quita los 0 que no nos sirven\n",
    "    df['Monto1'] = df['Monto1'].map(lambda x: ('%.2f' % x).rstrip('0').rstrip('.') if '.' in ('%.2f' % x) else '%.2f' % x)\n",
    "    \n",
    "    #Vamos a hacer la consulta de teradata por cuenta, por lo que el segundo parametro no importa ahorita (no importa la tarjeta por eso los 0000000)\n",
    "    df_teradata = consultar_teradata(consultar_por_cuenta)\n",
    "    #Hace los cruces con teradata usando la llave completa, cuenta como uno de los parametros\n",
    "    #En caso de que no encuentre en teradata, hace los cruces con cuenta&aut y asigna las fehcas y montos\n",
    "    #Identifica los que aun asi  noestan\n",
    "    #Se indica que no se van a corregir las cuentas con el false\n",
    "    df_bien, df_mal, df_errores_cuenta, df_teradata = cruces(df, df_teradata, \"CTA\", \"Cuenta\", False)\n",
    "    df_aut_mal,df_no_estan, df_errores_aut, df_teradata = corregir_aut(df_mal, df_teradata, \"CTA\", \"Cuenta\")\n",
    "    df_mal,df_no_estan, df_errores_monto_fecha = correccion_datos(df_no_estan,df_teradata, \"CTA\", \"Cuenta\")\n",
    "\n",
    "    #Hace los cruces con teradata usando la llave completa, tarjeta como uno de los parametros\n",
    "    #En caso de que no encuentre en teradata, hace los cruces con tarjeta&aut y asigna las fehcas y montos\n",
    "    #Identifica los que aun asi  noestan\n",
    "    #Vamos a hacer la consulta de teradata por tarjeta, por lo que el segundo parametro no importa ahorita (no importa la cuenta por eso los 0000000)\n",
    "    #Se indica que no se van a corregir las cuentas con el false\n",
    "    df_teradata = consultar_teradata(consultar_por_tarjeta)\n",
    "    df_teradata = quitar_corregidos_en_teradata(df_bien, df_aut_mal, df_mal, df_teradata)\n",
    "    print(\"\\n\\tCargando archivo\")\n",
    "    df_cuentas_mal, df_todo_mal, df_errores_cuenta, df_teradata = cruces(df_no_estan, df_teradata, \"PAN\", \"Tarjeta\", True)\n",
    "    df_aut_cuenta_mal,df_cuen_fech_impo_mal, df_errores_cuenta_aut, df_teradata = corregir_aut(df_todo_mal,df_teradata, \"PAN\", \"Tarjeta\")\n",
    "    df_cuen_fech_impo_mal,df_no_estan, df_errores_cuenta_fecha_monto = correccion_datos(df_cuen_fech_impo_mal,df_teradata, \"PAN\", \"Tarjeta\")\n",
    "    \n",
    "    #Concatenar todos los df corregidos en uno solo (menos el completo y los manuales) \n",
    "    df_corregidos = pd.concat([\n",
    "        df_bien,\n",
    "        df_mal,\n",
    "        df_cuentas_mal,\n",
    "        df_cuen_fech_impo_mal,\n",
    "        df_aut_mal,\n",
    "        df_aut_cuenta_mal\n",
    "    ], ignore_index=True)\n",
    "    \n",
    "\n",
    "    df_corregidos, df_duplicados = quitar_duplicados(df_corregidos)\n",
    "    \n",
    "    url = r\"\\\\celerrabr\\Compartido\\Entre_Sesiones\\D7627S042\\MIS Operaciones\\Parcializaciones\\Angelica\\Parcializacion\\B -Bases CTS trabajadas\"\n",
    "    nombre = \"\\casos.xlsx\"\n",
    "    url_archivo = url + nombre\n",
    "    \n",
    "    df_errores = pd.DataFrame(columns=[\"Aquí van a ir los errores\"])\n",
    "    df_itim = pd.DataFrame(columns=[\"Aquí van a ir el itim\"])\n",
    "\n",
    "    #df_corregidos = asignar_secuencia_tienda(df_corregidos)\n",
    "    \n",
    "    #Exporta el archivo con todos los df, se hacen los casos manuales y se agregan a la hoja de \"Todos corregidos\" del excel, luego compara todos con el historico\n",
    "    exportar_archivo(df,df_no_estan,df_corregidos,df_errores,df_itim, url_archivo)\n",
    "    \n",
    "    input(\"\\n\\tCORRIJA Y AGREGUE LOS CASOS MANUALES / APRIETE CUALQUIER TECLA PARA CONTINUAR\")\n",
    "    \n",
    "    dtype = {\n",
    "        'Cuenta' : str,\n",
    "        'Tarjeta' : str,\n",
    "        'Autorizacion1' : str,\n",
    "        'Llave_completa' : str,\n",
    "        'Llave' : str,\n",
    "        \n",
    "        }\n",
    "\n",
    "    #Lee los archivos tal cual como vienen en el sharepoint\n",
    "    df_corregidos = pd.read_excel(url_archivo, dtype=dtype, sheet_name = \"Todos corregidos\")\n",
    "    df_corregidos[\"Fcompra1\"] = pd.to_datetime(df_corregidos[\"Fcompra1\"], errors='coerce', dayfirst=True)\n",
    "\n",
    "    \n",
    "    df_corregidos[\"Fcompra1\"] = df_corregidos[\"Fcompra1\"].dt.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "    print(\"\\n\\tAsignando secuencias\")\n",
    "    df_corregidos = asignar_secuencia_tienda(df_corregidos)\n",
    "    \n",
    "    print(\"\\n\\tCargando historico\")\n",
    "    df_corregidos, df_estan_historico = comparar_con_historico(df_corregidos)\n",
    "    \n",
    "    print(\"\\n\\tArmando Hoja Errores y hoja Itiim\")\n",
    "    df_errores = definir_errores(df_errores_aut, df_errores_monto_fecha, df_errores_cuenta, df_errores_cuenta_aut, df_errores_cuenta_fecha_monto, df_estan_historico,df_duplicados)\n",
    "    \n",
    "    df_itim = armar_itim(df_corregidos)\n",
    "    df_inclusiones = armar_inclusiones(df_corregidos)\n",
    "    df_itim = pd.concat([df_itim,df_inclusiones])\n",
    "\n",
    "    print(\"\\n\\tCargando archivo\")\n",
    "    exportar_archivo(df,df_no_estan,df_corregidos,df_errores,df_itim, url_archivo)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "def comparar_con_historico(df):\n",
    "\n",
    "    url = r\"\\\\celerrabr\\Compartido\\Entre_Sesiones\\D7627S042\\MIS Operaciones\\Parcializaciones\\Angelica\\Parcializacion\\B -Bases CTS trabajadas\"\n",
    "    nombre_historico = \"\\Historico.xlsx\"\n",
    "    url_historico = url + nombre_historico\n",
    "    \n",
    "    dtype = {\n",
    "        \"Cuenta\" : str,\n",
    "        \"Tarjeta\" : str,\n",
    "        \"Autorizacion1\": str,\n",
    "        \"PS\" : str,\n",
    "        \"Store\" : str,\n",
    "    }\n",
    "    \n",
    "    \n",
    "    #Que el historico sea de una sola hoja, no separada por socios\n",
    "    df_historico = pd.read_excel(url_historico, dtype=dtype, parse_dates=[\"Fcompra1\"])\n",
    "\n",
    "    #Poner las columnas fecha e importe con el mismo formato a los del df\n",
    "    df_historico['Fcompra1'] = pd.to_datetime(df_historico['Fcompra1'], dayfirst=True, errors='coerce')\n",
    "    df_historico['Fcompra1'] = df_historico['Fcompra1'].dt.strftime('%d/%m/%Y')\n",
    "    df_historico['Monto1'] = df_historico['Monto1'].map(lambda x: ('%.2f' % x).rstrip('0').rstrip('.') if '.' in ('%.2f' % x) else '%.2f' % x)\n",
    "\n",
    "    df['Fcompra1'] = pd.to_datetime(df['Fcompra1'], dayfirst=False, errors='coerce')\n",
    "    df['Fcompra1'] = df['Fcompra1'].dt.strftime('%d/%m/%Y')\n",
    "    df['Monto1'] = df['Monto1'].astype(float)\n",
    "    df['Monto1'] = df['Monto1'].map(lambda x: ('%.2f' % x).rstrip('0').rstrip('.') if '.' in ('%.2f' % x) else '%.2f' % x)\n",
    "    \n",
    "    \n",
    "    #Crear llave completa para el historico\n",
    "    df_historico[\"Llave_completa\"] = df_historico[\"Cuenta\"] + df_historico[\"Autorizacion1\"] + df_historico[\"Monto1\"].astype(str) + df_historico[\"Fcompra1\"].astype(str) + df_historico[\"Txn1\"].astype(str)\n",
    "    \n",
    "    #Creamos de nuevo la llave del df debido a que la anterior estaba con los datos incorrectos (Se corrigeron todos los datos menos los de la llave)\n",
    "    df[\"Llave_completa\"] = df[\"Cuenta\"] + df[\"Autorizacion1\"] + df[\"Monto1\"].astype(str) + df[\"Fcompra1\"].astype(str) + df[\"Txn1\"].astype(str)\n",
    "    \n",
    "    \n",
    "    #Elimina del df los que estan en el historico\n",
    "    df_estan_historico = df[df[\"Llave_completa\"].isin(set(df_historico['Llave_completa']))]\n",
    "    df = df[~df[\"Llave_completa\"].isin(set(df_historico['Llave_completa']))]\n",
    "    \n",
    "    df_estan_historico[\"Errores\"] = \"Ya esta parcializada\"\n",
    "    \n",
    "    exportar_historico(df,df_historico,url_historico)\n",
    "    \n",
    "    return df, df_estan_historico\n",
    "    \n",
    "def exportar_historico(df, df_historico, url):\n",
    "\n",
    "    df_hoy = df.drop(['Llave',  'Llave_completa'], axis=1)\n",
    "    df_historico = df_historico.drop(\"Llave_completa\", axis=1)\n",
    "    df_historico = pd.concat([df_hoy, df_historico], ignore_index=True)\n",
    "    \n",
    "    with pd.ExcelWriter(url) as writer:\n",
    "        df_historico.to_excel(writer, \"Historico\", index=False)\n",
    "\n",
    "    print(\"\\n\\tHistorico guardado con exito\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def asignar_secuencia_tienda(df):\n",
    "    \n",
    "    #Hace la consulta sql por cuenta\n",
    "    cuentas = formato_SQL(df,\"Cuenta\")\n",
    "    \n",
    "    conn = abrir_db()\n",
    "    df_sql = ejecutar_query(query_arqa(cuentas), conn)\n",
    "    cerrar_db(conn)\n",
    "    \n",
    "    #Da el formato a los campos importantes\n",
    "    df_sql['Fecha_Apertura_Plan'] = pd.to_datetime(df_sql['Fecha_Apertura_Plan'], dayfirst=True, errors='coerce')\n",
    "    df_sql[\"Plan_de_Venta\"] = df_sql[\"Plan_de_Venta\"].astype(int) \n",
    "    \n",
    "    df['Fcompra1'] = pd.to_datetime(df['Fcompra1'], dayfirst=True, errors='coerce')\n",
    "    \n",
    "    \n",
    "    #Crea las llaves para hacer cruces\n",
    "    df_sql[\"Llave\"] = df_sql[\"Numero_Cuenta\"] + df_sql[\"Plan_de_Venta\"].astype(str)\n",
    "    df[\"Llave\"] = df[\"Cuenta\"] + df[\"Txn1\"].astype(str)\n",
    "    \n",
    "    #Hace los cruces para traerse todas las tiendas y las secuencias de sql de todos los casos\n",
    "    df_con_secuencia = pd.merge(df, df_sql[[\"Llave\", \"Secuencia\", \"Store\", \"Fecha_Apertura_Plan\"]], on=\"Llave\", how=\"left\")\n",
    "    \n",
    "    #Elimina las que sean despues de la fecha de compra\n",
    "    df_con_secuencia = df_con_secuencia[df_con_secuencia['Fecha_Apertura_Plan'] <= df_con_secuencia['Fcompra1']]\n",
    "\n",
    "    #Ordena de mas reciente a mas antigua\n",
    "    df_con_secuencia = df_con_secuencia.sort_values(by='Fecha_Apertura_Plan', ascending=False)\n",
    "    \n",
    "    #Elimina duplicados dejando el primero para tener el mas reciente\n",
    "    df_con_secuencia = df_con_secuencia.drop_duplicates(subset = \"Llave_completa\", keep='first')\n",
    "\n",
    "    #Hacemos este cruce de nuuevo solo para ver si algun dato esta vacio\n",
    "    df =pd.merge(df,df_con_secuencia[[\"Llave_completa\", \"Secuencia\", \"Store\"]], on=\"Llave_completa\", how=\"left\")\n",
    "\n",
    "    df = df.rename(columns={'Secuencia': 'PS'})\n",
    "    \n",
    "    return df\n",
    "\n",
    "def armar_itim(df):\n",
    "\n",
    "    df_itim = pd.DataFrame()\n",
    "    df_itim[\"Cuenta\"] = df[\"Cuenta\"]\n",
    "    df_itim[\"Parcialidad\"] = \"0\"\n",
    "    df_itim[\"Fecha\"] =  df[\"Fcompra1\"]\n",
    "    df_itim[\"Monto de la compra\"] = df[\"Monto1\"]\n",
    "    df_itim[\"Plan\"] = df[\"Txn1\"]\n",
    "    df_itim[\"Secuencia\"] = df[\"PS\"]\n",
    "    df_itim[\"Tienda\"] = df[\"Store\"]\n",
    "    df_itim[[\"Transaccion\", \"Descripcion\"]] = df[\"TipoParcializacion\"].map({\n",
    "    \"PF\": (\"823\", \"AJUSTE POR PROMOCION PAGOS FIJOS        \"),\n",
    "    \"MSI\": (\"821\", \"AJUSTE PROMOCION SIN INTERES RED        \")\n",
    "    }).apply(pd.Series)\n",
    "\n",
    "    return df_itim\n",
    "\n",
    "def definir_plan_pf(parcialidad):\n",
    "\n",
    "    caso = {\n",
    "        \"3\": \"3103\",\n",
    "        \"6\": \"3116\",\n",
    "        \"9\": \"3104\",\n",
    "        \"12\": \"3102\"\n",
    "        \n",
    "    }\n",
    "\n",
    "    return caso[parcialidad]\n",
    "\n",
    "def definir_plan_msi(parcialidad):\n",
    "\n",
    "    caso = {\n",
    "        \"4\": \"3173\",\n",
    "        \"6\": \"3176\",\n",
    "        \"9\": \"3179\",\n",
    "        \"12\": \"3170\"\n",
    "    }\n",
    "\n",
    "    return caso[parcialidad]\n",
    "\n",
    "\n",
    "def armar_itim_inclusiones(df, tipo_parci):\n",
    "    \n",
    "    hoy = dt.now()\n",
    "    hoy = str(hoy.strftime(\"%d/%m/%Y\"))\n",
    "\n",
    "    df_inclusiones = pd.DataFrame()\n",
    "    \n",
    "    df_inclusiones[\"Cuenta\"] = df[\"Cuenta\"]\n",
    "    df_inclusiones[\"Parcialidad\"] = df[\"Pagos\"]\n",
    "    df_inclusiones[\"Fecha\"] = hoy\n",
    "    df_inclusiones[\"Monto de la compra\"] = df[\"Monto1\"]\n",
    "    df_inclusiones[\"Secuencia\"] = \"0\"\n",
    "    df_inclusiones[\"Tienda\"] = df[\"Store\"]\n",
    "    if tipo_parci == \"PF\":\n",
    "        plan = []\n",
    "        for index,row in df.iterrows():\n",
    "            plan.append(definir_plan_pf(str(row[\"Pagos\"])))\n",
    "        df_inclusiones[\"Plan\"] = plan\n",
    "        df_inclusiones[\"Transaccion\"] = \"822\"\n",
    "        df_inclusiones[\"Descripcion\"] = \"INC PROMOCION PAGOS FIJOS               \"\n",
    "    else:\n",
    "        plan = []\n",
    "        for index,row in df.iterrows():\n",
    "            plan.append(definir_plan_msi(str(row[\"Pagos\"])))\n",
    "        df_inclusiones[\"Plan\"] = plan\n",
    "        df_inclusiones[\"Transaccion\"] = \"820\"\n",
    "        df_inclusiones[\"Descripcion\"] = \"INC PROMOCION MSI                       \"\n",
    "\n",
    "    return df_inclusiones\n",
    "\n",
    "def armar_inclusiones(df):\n",
    "\n",
    "    df[\"Cuenta_parci\"] = df[\"Cuenta\"].astype(str) + df[\"Pagos\"].astype(str)\n",
    "    df[\"Monto1\"] = df[\"Monto1\"].astype(float)\n",
    "    df = df.groupby(\"Cuenta_parci\", as_index=False).agg({\n",
    "    \"Monto1\": \"sum\",\n",
    "    \"Cuenta\": \"first\",\n",
    "    \"Pagos\": \"first\",\n",
    "    \"Txn1\": \"first\",\n",
    "    \"Store\": \"first\",\n",
    "    \"TipoParcializacion\": \"first\"\n",
    "    })\n",
    "\n",
    "    \n",
    "    #Separarlas por df o MSI\n",
    "    df_pf = df[df[\"TipoParcializacion\"] == \"PF\"].copy()\n",
    "    df_msi = df[df[\"TipoParcializacion\"] == \"MSI\"].copy()\n",
    "\n",
    "    df_pf_inclusiones = armar_itim_inclusiones(df_pf, \"PF\")\n",
    "    df_msi_inclusiones = armar_itim_inclusiones(df_msi, \"MSI\")\n",
    "    \n",
    "    #Concatenar los dos df\n",
    "    df_inclusiones = pd.concat([df_pf_inclusiones,df_msi_inclusiones])\n",
    "\n",
    "    return df_inclusiones\n",
    "    \n",
    "    \n",
    "    \n",
    "def main():\n",
    "    \n",
    "    \n",
    "    #Para no hacer todo dos veces en caso de qu los df se deban mantener separados, se puede crear una funcion en donde se ponga \n",
    "    #todos los pasos y de parametro reciba un df, finalmente en el main llamamos a esa funcio dos veces una por cada df\n",
    "    warnings.filterwarnings('ignore')\n",
    "    df_prove = leer_archivos()\n",
    "    proceso(df_prove)\n",
    "    \n",
    "    #print(df_bien)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "main()\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
